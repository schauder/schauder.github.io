---
layout: default
status: publish
published: true
title: Fehlerrechnung, Statistik und Messbarkeit von Produktivit&Atilde;&curren;t
author:
  display_name: Jens Schauder
  login: admin
  email: jens@schauderhaft.de
  url: http://blog.schauderhaft.de
author_login: admin
author_email: jens@schauderhaft.de
author_url: http://blog.schauderhaft.de
wordpress_id: 44
wordpress_url: http://blog.schauderhaft.de/2008/07/13/fehlerrechnung-statistik-und-messbarkeit-von-produktivitat/
date: '2008-07-13 20:04:45 +0200'
date_gmt: '2008-07-13 19:04:45 +0200'
categories:
- article
- Softwareentwicklung
- Quality Management
- Statistik
tags: []
comments: []
---
<p>Martin Fowler vertritt die These, man <a href="http:&#47;&#47;martinfowler.com&#47;bliki&#47;CannotMeasureProductivity.html">k&Atilde;&para;nne Produktivit&Atilde;&curren;t nicht messen<&#47;a>. <a href="http:&#47;&#47;www.wissenslogs.de&#47;wblogs&#47;blog&#47;mathematik-im-alltag&#47;allgemein&#47;2008-02-12&#47;als-physikerin-sage-ich">Als Physiker sage ich<&#47;a>: "I beg to differ Mr Fowler!" Sein zentrales Argument ist, dass es nicht m&Atilde;&para;glich sei das Ergebnis der Softwareentwicklung zu messen.  Das erscheint mir dann doch arg fatalistisch. Wir sind in der Lage, Spektralanalysen von Sternen durchzuf&Atilde;&frac14;hren, die wir mit dem blo&Atilde;&Yuml;en Auge nicht einmal ann&Atilde;&curren;hernd sehen k&Atilde;&para;nnen, wir messen alles und jeden mit einer Genauigkeit die einfach unvorstellbar ist, aber Softwareentwicklung, oder besser, deren Ergebnis soll unmessbar sein? Wohl kaum. Was sicherlich richtig ist: Es ist schwer Produktivit&Atilde;&curren;t genau zu messen. Softwareentwicklung ist ein kreativer Prozess und es liegt in der Natur der Sache, dass ein St&Atilde;&frac14;ck Software nie zweimal unter vergleichbaren Bedingungen erstellt wird. Deswegen wird es wohl in der Tat keine Messung geben der Art, dass der Chef mit einer Art Geigerz&Atilde;&curren;hler durch die B&Atilde;&frac14;ro's l&Atilde;&curren;uft und misst wo, denn die Produktivit&Atilde;&curren;t verloren geht. Ein bisschen mehr Aufwand wird wohl notwendig sein.</p>
<p>Das erste Problem ist die Definition der Produktivit&Atilde;&curren;t, und dies ist der Punkt, an dem Martin Fowler glaubt zu scheitert. Er macht verschiedene Vorschl&Atilde;&curren;ge:</p>
<ul>
<li>Lines of Code pro Person und Zeit<&#47;li>
<li>Function Points pro Person und Zeit<&#47;li>
<li>Nutzen f&Atilde;&frac14;r den Kunden pro Person und Zeit<&#47;li>
<li>langfristiger Nutzen f&Atilde;&frac14;r den Kunden pro Person und Zeit (hier spielen Wartbarkeit und Anpassbarkeit hinein)<&#47;li><br />
<&#47;ul><br />
Das ist aber in keiner Weise ein prinzipielles Problem! Es ist einfache eine Frage von: Was will ich eigentlich wissen? Auch um Elektrizit&Atilde;&curren;t zu messen gibt es verschiedene Ans&Atilde;&curren;tze: Spannung, Strom, Leistung, Kapazit&Atilde;&curren;t ... es ist die Aufgabe dessen, der die Messung vornimmt, zuvor zu bestimmen, was er messen will.</p>
<p>Wenn ich die Produktivit&Atilde;&curren;t von zwei Programmiersprachen vergleichen will sind Lines Of Code vermutlich ein schlechte Ma&Atilde;&Yuml;einheit, da sie zwischen zwei Sprachen nicht vergleichbar ist.  Aber wenn ich zwei Java IDEs miteinander vergleichen m&Atilde;&para;chte k&Atilde;&para;nnte, dies ein sehr einfaches, direktes und aussagekr&Atilde;&curren;ftiges Ma&Atilde;&Yuml; sein. Wenn ich die Leistungsf&Atilde;&curren;higkeit eines Teams, oder einer Methode beurteilen m&Atilde;&para;chte, dann ist es vermutlich sinnvoll eine ganze Reihe von Ma&Atilde;&Yuml;zahlen zur Beurteilung heranzuziehen. Schlie&Atilde;&Yuml;lich wird eine Stromquelle typischerweise auch durch wenigstens zwei Gr&Atilde;&para;&Atilde;&Yuml;en (Strom und Spannung) gekennzeichnet.  Leider gibt es bisher wenig brauchbare Standards f&Atilde;&frac14;r diese Fragestellung, so dass wohl jeder, der sich f&Atilde;&frac14;r dieses Thema interessiert seine eigenen Ma&Atilde;&Yuml;einheiten definieren muss.</p>
<p>Ein weiteres Indiz, welches Fowler anf&Atilde;&frac14;hrt, als Beleg der Unmessbarkeit von Softwareentwicklung, w&Atilde;&frac14;rde ich als Physiker einfach als statistischen Fehler bezeichnen. Er f&Atilde;&frac14;hrt Beispiele an, bei denen verschiedene <a href="http:&#47;&#47;de.wikipedia.org&#47;wiki&#47;Function_Point_Analyse">Function Point Analysen<&#47;a> Abweichungen von 300% hatten. Ist doch wunderbar, bei Experimenten im Physikpraktikum zum <a href="http:&#47;&#47;de.wikipedia.org&#47;wiki&#47;Foucaultsches_Pendel">Foucaultschen Pendel<&#47;a> haben einige Gruppen festgestellt, das Bielefeld auf der S&Atilde;&frac14;dhalbkugel, bzw. jenseits des Nordpols liegen. &Atilde;&oelig;ber 300% Messfehler h&Atilde;&curren;tten wir nur gel&Atilde;&curren;chelt. Aber ernsthaft, es gibt ein recht einfaches Mittel gegen solche Fehler: Mehrfach messen. Wenn eine Messung von X vom wahren Wert um d Prozent abweicht, so weicht der Durchschnitt aus n Messungen nur noch um 1&#47;sqrt(d) ab. (Kann man in HTML eigentlich mittlerweile vern&Atilde;&frac14;nftig Formeln schreiben?) Wenn ich jetzt mal davon ausgehe, dass die 300% Messfehler ein Extremwert ist, und ein typischer Wert, bei -25% bis +50% liegt, so kommt man schon recht schnell in brauchbare Gebiete. Vor allem, da exakte Werte (in welcher Einheit auch immer) meist gar nicht so relevant sind. Meist sind die Fragestellungen ja eher in der Art: Ist Test First, besser als Test last? Ist Agil besser als Wasserfall? Ist Ruby besser als Java? Wenn man eine solche Fragestellung an einigen Projekten untersucht, die sich ansonsten wenig unterscheiden, kommt man mit guter Wahrscheinlichkeit z&Atilde;&frac14;gig zu einem belastbaren Ergebnis.</p>
<p>ABER, ja leider kommt jetzt doch noch das gro&Atilde;&Yuml;e ABER. Die Softwarebranche ist noch hochgradig dynamisch. St&Atilde;&curren;ndig kommen neue Sprachen, Betriebssysteme, Frameworks, Methoden und dergleichen mehr auf den Markt, so dass zwei Projekte nur selten ausreichend &Atilde;&curren;hnlich sind, um direkte R&Atilde;&frac14;ckschl&Atilde;&frac14;sse auf die Auswirkungen eines Parameters auf die Produktivit&Atilde;&curren;t zu zu lassen. Eine Analyse w&Atilde;&curren;re nur mit entsprechendem statistischen Aufwand und&#47;oder unter kontrollierten Bedingungen m&Atilde;&para;glich, beides ist in Mittelst&Atilde;&curren;ndischen Unternehmen meist nicht praktikabel.</p>
<p>Als Quintessenz bleibt also Produktivit&Atilde;&curren;t IST messbar, allerdings werden die Kosten f&Atilde;&frac14;r eine solche Messung h&Atilde;&curren;ufig als h&Atilde;&para;her als der Nutzen eingesch&Atilde;&curren;tzt. Nicht viel besser, aber weniger fatalistisch als die Aussage von Martin Fowler.</p>
